{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Quick Tip #004: Using Custom Transformers in Scikit-Learn Pipelines!\n",
    "In our last post, we covered how to use Scikit-Learn pipelines to conjoin all the appropriate transformers into a single output. In this new post, we'll take things a step further by adding custom transformers to the pipeline. Because this is very much building on top of the last post, much of this code should already appear to be familiar to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup\n",
    "Let's go ahead and import the libraries we'll be using as well as the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries we'll be using for this project\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training dataset\n",
    "raw_train = pd.read_csv('../data/titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data into appropriate training and validation sets\n",
    "X = raw_train.drop(columns = ['Survived'])\n",
    "y = raw_train[['Survived']]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>Saalfeld, Mr. Adolphe</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19988</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>C106</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>2</td>\n",
       "      <td>Hamalainen, Mrs. William (Anna)</td>\n",
       "      <td>female</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>250649</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>479</td>\n",
       "      <td>3</td>\n",
       "      <td>Karlsson, Mr. Nils August</td>\n",
       "      <td>male</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350060</td>\n",
       "      <td>7.5208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                             Name     Sex    Age  \\\n",
       "298          299       1            Saalfeld, Mr. Adolphe    male    NaN   \n",
       "884          885       3           Sutehall, Mr. Henry Jr    male  25.00   \n",
       "247          248       2  Hamalainen, Mrs. William (Anna)  female  24.00   \n",
       "478          479       3        Karlsson, Mr. Nils August    male  22.00   \n",
       "305          306       1   Allison, Master. Hudson Trevor    male   0.92   \n",
       "\n",
       "     SibSp  Parch           Ticket      Fare    Cabin Embarked  \n",
       "298      0      0            19988   30.5000     C106        S  \n",
       "884      0      0  SOTON/OQ 392076    7.0500      NaN        S  \n",
       "247      0      2           250649   14.5000      NaN        S  \n",
       "478      0      0           350060    7.5208      NaN        S  \n",
       "305      1      2           113781  151.5500  C22 C26        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing first few rows of X_train dataset\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived\n",
       "298         1\n",
       "884         0\n",
       "247         1\n",
       "478         0\n",
       "305         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing first few rows of y_train dataset\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Our Pipeline (Now With Custom Transformers!)\n",
    "With our data imported, we're ready to go ahead and start creating our pipeline. As mentioned above, we'll only be using the default transformers here, so we definitely won't be getting great results out of our model predictions. But that's okay! The purpose here is learning how to use a pipeline.\n",
    "\n",
    "Note: You might be wondering in the next cell why we're creating a column transformer for a single column. This is because in the next post, we'll be adding custom transformers making use of mostly the same code you'll see below. (With a few additions!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to appropriately engineer the 'Age' column\n",
    "def create_age_bins(col):\n",
    "    '''Engineers age bin variables for pipeline'''\n",
    "    \n",
    "    # Defining / instantiating the necessary variables\n",
    "    age_bins = [-1, 12, 18, 25, 50, 100]\n",
    "    age_labels = ['child', 'teen', 'young_adult', 'adult', 'elder']\n",
    "    age_imputer = SimpleImputer(strategy = 'median')\n",
    "    age_ohe = OneHotEncoder()\n",
    "    \n",
    "    # Performing basic imputation for nulls\n",
    "    imputed = age_imputer.fit_transform(col)\n",
    "    ages_filled = pd.DataFrame(data = imputed, columns = ['Age'])\n",
    "    \n",
    "    # Segregating ages into age bins\n",
    "    age_cat_cols = pd.cut(ages_filled['Age'], bins = age_bins, labels = age_labels)\n",
    "    age_cats = pd.DataFrame(data = age_cat_cols, columns = ['Age'])\n",
    "    \n",
    "    # One hot encoding new age bins\n",
    "    ages_encoded = age_ohe.fit_transform(age_cats[['Age']])\n",
    "    ages_encoded = pd.DataFrame(data = ages_encoded.toarray())\n",
    "    \n",
    "    return ages_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to appropriately engineer the 'Embarked' column\n",
    "def create_embarked_columns(col):\n",
    "    '''Engineers the embarked variables for pipeline'''\n",
    "    \n",
    "    # Instantiating the transformer objects\n",
    "    embarked_imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "    embarked_ohe = OneHotEncoder()\n",
    "    \n",
    "    # Performing basic imputation for nulls\n",
    "    imputed = embarked_imputer.fit_transform(col)\n",
    "    embarked_filled = pd.DataFrame(data = imputed, columns = ['Embarked'])\n",
    "    \n",
    "    # Performing OHE on the col data\n",
    "    embarked_columns = embarked_ohe.fit_transform(embarked_filled[['Embarked']])\n",
    "    embarked_columns_df = pd.DataFrame(data = embarked_columns.toarray())\n",
    "    \n",
    "    return embarked_columns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a preprocessor to transform the 'Sex' column\n",
    "data_preprocessor = ColumnTransformer(transformers = [\n",
    "    ('sex_transformer', OneHotEncoder(), ['Sex']),\n",
    "    ('age_transformer', FunctionTransformer(create_age_bins, validate = False), ['Age']),\n",
    "    ('embarked_transformer', FunctionTransformer(create_embarked_columns, validate = False), ['Embarked'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our pipeline that first preprocesses the data, then scales the data, then fits the data to a RandomForestClassifier\n",
    "rfc_pipeline = Pipeline(steps = [\n",
    "    ('data_preprocessing', data_preprocessor),\n",
    "    ('data_scaling', StandardScaler()),\n",
    "    ('model', RandomForestClassifier(max_depth = 10,\n",
    "                                     min_samples_leaf = 3,\n",
    "                                     min_samples_split = 4,\n",
    "                                     n_estimators = 200))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dkhundley/opt/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('data_preprocessing',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('sex_transformer',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=True),\n",
       "                                                  ['Sex']),\n",
       "                                                 ('age_transformer',\n",
       "                                                  FunctionTransformer(accept_sparse=False...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=10, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=3, min_samples_split=4,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=200, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the training data to our pipeline\n",
    "rfc_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/rfc_pipeline.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving our pipeline to a binary pickle file\n",
    "joblib.dump(rfc_pipeline, 'model/rfc_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading back in our serialized model\n",
    "loaded_model = joblib.load('model/rfc_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7847533632286996\n",
      "ROC AUC Score: 0.7775029347643804\n",
      "Confusion Matrix: \n",
      "[[109  25]\n",
      " [ 23  66]]\n"
     ]
    }
   ],
   "source": [
    "# Checking out our predicted results using the validation dataset\n",
    "pipeline_preds = loaded_model.predict(X_val)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, pipeline_preds)\n",
    "val_roc_auc = roc_auc_score(y_val, pipeline_preds)\n",
    "val_confusion_matrix = confusion_matrix(y_val, pipeline_preds)\n",
    "\n",
    "print(f'Accuracy Score: {val_accuracy}')\n",
    "print(f'ROC AUC Score: {val_roc_auc}')\n",
    "print(f'Confusion Matrix: \\n{val_confusion_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
